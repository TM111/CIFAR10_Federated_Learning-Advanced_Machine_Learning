{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DWwypvPVTp5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90d589ff-97c1-4b50-cf5c-3a1b056128f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchvision) (3.10.0.2)\n",
            "Requirement already satisfied: Pillow-SIMD in /usr/local/lib/python3.7/dist-packages (9.0.0.post1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install 'torch'\n",
        "!pip3 install 'torchvision'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xW98mYNis-RX"
      },
      "source": [
        "PARAMETERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5mYvkqes9ob"
      },
      "outputs": [],
      "source": [
        "DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
        "\n",
        "NUM_CLASSES = 10   \n",
        "\n",
        "BATCH_SIZE = 100     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = 0.001      # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = 30   # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 5    # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = 30\n",
        "\n",
        "MODEL = \"LeNet5\"   #change model (LeNet5, mobilenetV2)\n",
        "\n",
        "NUM_CLIENTS = 100\n",
        "\n",
        "NUM_SELECTED_CLIENTS = 3 #NUM CLIENTS FOR ROUND\n",
        "\n",
        "ROUNDS = 6"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREPARE DATASET"
      ],
      "metadata": {
        "id": "cnq8b0oIWRDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms as transforms\n",
        "import torchvision\n",
        "import torch.utils.data\n",
        "\n",
        "train_transform =  transforms.Compose([transforms.ToTensor()])\n",
        "test_transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_set = torchvision.datasets.CIFAR10(root='./CIFAR10', train=True, download=True, transform=train_transform)\n",
        "test_set = torchvision.datasets.CIFAR10(root='./CIFAR10', train=False, download=True, transform=test_transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Check dataset sizes\n",
        "print('Train Dataset: {}'.format(len(train_set)))\n",
        "print('Test Dataset: {}'.format(len(test_set)))\n"
      ],
      "metadata": {
        "id": "Fy3LuyaqWQft",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "5a492e9719734fefa09dc484a948ffd2",
            "11d1c59cc4f64daca63f797d055c9e1f",
            "0e4ba3ef028f41b7b19cf979909a693b",
            "25b2c0b32e23466ab14e0801df40e6b7",
            "94f7eb5293f1476ca5ea50da4d24f747",
            "48e62ec7737a44a4b44841d448b6120a",
            "df4441df8172419bb026a37ff075c5f8",
            "5257aa416ce94a18b593d2ae335a98fd",
            "76a4087ba1cf40b1bd424216d858cbbb",
            "ee751978540d4ababba8de8f28a46232",
            "c1b1b3fb4b9a4ed0ba70eb3f587c2f96"
          ]
        },
        "outputId": "deecf309-7c4a-4e78-e8c2-d08aaa7c5021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./CIFAR10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a492e9719734fefa09dc484a948ffd2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./CIFAR10/cifar-10-python.tar.gz to ./CIFAR10\n",
            "Files already downloaded and verified\n",
            "Train Dataset: 50000\n",
            "Test Dataset: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DEFINE MODELS**\n",
        "\n",
        "*Here we define the networks (LeNet5, mobilenetV2)*"
      ],
      "metadata": {
        "id": "6ZmtPZcHH8fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import argparse\n",
        "from statistics import mean \n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as func\n",
        "\n",
        "#DEFINE NETWORKS\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(16*5*5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = func.relu(self.conv1(x))\n",
        "        x = func.max_pool2d(x, 2)\n",
        "        x = func.relu(self.conv2(x))\n",
        "        x = func.max_pool2d(x, 2)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = func.relu(self.fc1(x))\n",
        "        x = func.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "def mobilenetV2(pretrain=True):\n",
        "  model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=pretrain)\n",
        "  return model\n",
        "\n",
        "def get_net():\n",
        "  if(MODEL==\"LeNet5\"):\n",
        "    return LeNet5()\n",
        "  elif (MODEL==\"mobilenetV2\"):\n",
        "    return mobilenetV2()\n",
        "\n",
        "    \n",
        "#DEFINE TEST FUNCTION\n",
        "def evaluate(net, criterion,dataloader,  print_tqdm = True):\n",
        "  with torch.no_grad():\n",
        "    net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "    net.train(False) # Set Network to evaluation mode\n",
        "    running_corrects = 0\n",
        "    #iterable = tqdm(dataloader) if print_tqdm else dataloader\n",
        "    losses = []\n",
        "    for images, labels in dataloader: \n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "      # Forward Pass\n",
        "      outputs = net(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "      losses.append(loss.item())\n",
        "      # Get predictions\n",
        "      _, preds = torch.max(outputs.data, 1)\n",
        "      # Update Corrects\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "    # Calculate Accuracy\n",
        "    accuracy = running_corrects / float(len(dataloader.dataset))\n",
        "  return mean(losses),accuracy"
      ],
      "metadata": {
        "id": "9sqkE-UQDapv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CENTRALIZED MODEL**\n",
        "\n",
        "experiment with a standard approach. Create a model and train"
      ],
      "metadata": {
        "id": "Ytsl8NJ8Y3Z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#STANDARD APPROACH\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.backends import cudnn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from statistics import mean \n",
        "import torch.nn.functional as func\n",
        "\n",
        "centralized_model = get_net()\n",
        "\n",
        "centralized_optimizer = torch.optim.SGD(centralized_model.parameters(), lr=LR, momentum=MOMENTUM)\n",
        "centralized_criterion = nn.CrossEntropyLoss()\n",
        "scheduler = optim.lr_scheduler.StepLR(centralized_optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "\n",
        "centralized_model = centralized_model.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "\n",
        "cudnn.benchmark # Calling this optimizes runtime\n",
        "\n",
        "\n",
        "# Start iterating over the epochs\n",
        "for epoch in range(0,NUM_EPOCHS):\n",
        "  print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_last_lr()))\n",
        "  # Iterate over the dataset\n",
        "  for images, labels in train_loader:\n",
        "    # Bring data over the device of choice\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    centralized_model.train() # Sets module in training mode\n",
        "\n",
        "    centralized_optimizer.zero_grad() # Zero-ing the gradients\n",
        "\n",
        "    # Forward pass to the network\n",
        "    outputs = centralized_model(images)\n",
        "    # Compute loss based on output and ground truth\n",
        "    loss = centralized_criterion(outputs, labels)\n",
        "\n",
        "    # Compute gradients for each layer and update weights\n",
        "    loss.backward()  # backward pass: computes gradients\n",
        "    centralized_optimizer.step() # update weights based on accumulated gradients\n",
        "  # Step the scheduler\n",
        "  scheduler.step()\n",
        "  loss,accuracy = evaluate(centralized_model,centralized_criterion, test_loader)\n",
        "  print('\\nTest Accuracy: {}'.format(accuracy)) \n",
        "\n",
        "centralized_accuracy=accuracy"
      ],
      "metadata": {
        "id": "LgMRrHW9iKr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DIRICHLET DISTRIBUTION\n",
        "\n",
        "Here we have the split of dataset based on dirichlet distribution\n",
        "\n",
        "https://github.com/google-research/google-research/tree/master/federated_vision_datasets"
      ],
      "metadata": {
        "id": "gJbAALaLP6eA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import csv\n",
        "from os import path\n",
        "import os\n",
        "import urllib.request \n",
        "import zipfile\n",
        "import random\n",
        "\n",
        "\n",
        "def cifar_parser(line, is_train=True):\n",
        "  if is_train:\n",
        "    user_id, image_id, class_id = line\n",
        "    return user_id, image_id, class_id\n",
        "  else:\n",
        "    image_id, class_id = line\n",
        "    return image_id, class_id\n",
        "\n",
        "\n",
        "def dirichlet_distribution(alpha):    # generate trainset split from csv\n",
        "  #download csv files\n",
        "  url=\"http://storage.googleapis.com/gresearch/federated-vision-datasets/cifar10_v1.1.zip\"\n",
        "  dir=\"/content/cifar10_csv\"\n",
        "  try:\n",
        "    os.mkdir(dir)\n",
        "  except:\n",
        "    print(\"Folder already exist\")\n",
        "\n",
        "  urllib.request.urlretrieve(url, \"/content/cifar10_csv/cifar.zip\")\n",
        "  with zipfile.ZipFile(\"/content/cifar10_csv/cifar.zip\",\"r\") as zip_ref:\n",
        "      zip_ref.extractall(\"/content/cifar10_csv\")\n",
        "\n",
        "  train_file=\"cifar10_csv/federated_train_alpha_\"+alpha+\".csv\"\n",
        "  \"\"\"Inspects the federated train split.\"\"\"\n",
        "  print('Train file: %s' % train_file)\n",
        "  if not path.exists(train_file):\n",
        "    print('Error: file does not exist.')\n",
        "    return\n",
        "  user_images={}\n",
        "  with open(train_file) as f:\n",
        "    reader = csv.reader(f)\n",
        "    next(reader)  # skip header.\n",
        "    for line in reader:\n",
        "      user_id, image_id, class_id = cifar_parser(line, is_train=True)\n",
        "      if(user_id not in user_images.keys()):\n",
        "        user_images[user_id]=[]\n",
        "      user_images[user_id].append(int(image_id))\n",
        "  return user_images\n",
        "\n",
        "def cifar_iid(): # all clients have all classes with the same data distribution\n",
        "  user_images={}\n",
        "  classes_dict={}\n",
        "  for i in range(len(train_set)):\n",
        "    label=train_set[i][1]\n",
        "    if(label not in classes_dict.keys()):\n",
        "      classes_dict[label]=[]\n",
        "    classes_dict[label].append(i)\n",
        "  classes_index=[]\n",
        "  for label in classes_dict.keys():\n",
        "    classes_index+=classes_dict[label]\n",
        "\n",
        "  count=0\n",
        "  for i in classes_index:\n",
        "    if(str(count) not in user_images.keys()):\n",
        "      user_images[str(count)]=[]\n",
        "    user_images[str(count)].append(i)\n",
        "    count+=1\n",
        "    if(count==NUM_CLIENTS):\n",
        "      count=0\n",
        "  return user_images\n",
        "\n",
        "def cifar_noniid(): # all clients have a number of class beetwen 1 and 4 with the same data distribution\n",
        "  user_images=cifar_iid()\n",
        "  for key in user_images.keys():\n",
        "    n_classes=random.randint(1,4)\n",
        "    list_of_class=random.sample(range(0, NUM_CLASSES), n_classes)\n",
        "    new_index_list=[]\n",
        "    for i in user_images[key]:\n",
        "      label=int(train_set[i][1])\n",
        "      if(label in list_of_class):\n",
        "        new_index_list.append(i)\n",
        "    user_images[key]=new_index_list\n",
        "  return user_images\n",
        "\n",
        "\n",
        "#CHOOSE ONE OF THEM DISTRIBUTION\n",
        "distribution=3\n",
        "\n",
        "if(distribution==1):  # https://github.com/google-research/google-research/tree/master/federated_vision_datasets\n",
        "  train_user_images=dirichlet_distribution(alpha='0.10') #'0.00', '0.05', '0.10', '0.20', '0.50', '1.00', '10.00', '100.00'\n",
        "\n",
        "elif(distribution==2):\n",
        "  train_user_images=cifar_iid()\n",
        "\n",
        "elif(distribution==3):  # https://towardsdatascience.com/preserving-data-privacy-in-deep-learning-part-2-6c2e9494398b\n",
        "  train_user_images=cifar_noniid()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader_list={}   #TRAIN LOADER DICT\n",
        "for user_id in train_user_images.keys():\n",
        "  dataset_ = torch.utils.data.Subset(train_set, train_user_images[user_id])\n",
        "  dataloader = torch.utils.data.DataLoader(dataset=dataset_, batch_size=BATCH_SIZE, shuffle=False)\n",
        "  train_loader_list[user_id]=dataloader"
      ],
      "metadata": {
        "id": "hJ9I5VDpP1ML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINE CLIENTS\n",
        "\n",
        "Creation of pool of clients"
      ],
      "metadata": {
        "id": "olLeAhvWrDjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generated_test_distribution(classes, num_samples):    # generate testset with specific class and size\n",
        "  test_user_images=[]\n",
        "  count=0\n",
        "  for c in classes:\n",
        "    count+=1\n",
        "    for i in range(len(test_set)):\n",
        "      if(test_set[i][1]==c):\n",
        "        test_user_images.append(i)\n",
        "      if(len(test_user_images)==int(num_samples/len(classes)+1)*count):\n",
        "        break\n",
        "  dataset_ = torch.utils.data.Subset(test_set, test_user_images)\n",
        "  dataloader = torch.utils.data.DataLoader(dataset=dataset_, batch_size=BATCH_SIZE, shuffle=False)\n",
        "  return dataloader\n",
        "\n",
        "\n",
        "#Client datastructure\n",
        "class Client():\n",
        "    def __init__(self, id,net,train_lr,optimizer,criterion):\n",
        "        self.id = id\n",
        "        self.net=net\n",
        "        self.train_loader=train_lr\n",
        "\n",
        "        classes=[]\n",
        "        for data in train_lr.dataset:\n",
        "          if(data[1] not in classes):\n",
        "            classes.append(data[1])\n",
        "        self.test_loader=generated_test_distribution(classes, int(len(train_lr.dataset)*0.15)) #specific testset for each clients\n",
        "\n",
        "        self.optimizer=optimizer\n",
        "        self.criterion=criterion\n",
        "\n",
        "\n",
        "#Istance list of clients\n",
        "clients_list=[]\n",
        "for i in range(NUM_CLIENTS):\n",
        "  net=get_net()\n",
        "  opt = torch.optim.SGD(net.parameters(), lr=LR, momentum=MOMENTUM)\n",
        "  crt=nn.CrossEntropyLoss()\n",
        "  client=Client(i,net,train_loader_list[str(i)],opt,crt)\n",
        "  clients_list.append(client)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ind=4\n",
        "l=[0,0,0,0,0,0,0,0,0,0]\n",
        "for i in range(len(clients_list[ind].train_loader.dataset)):\n",
        "  index=clients_list[ind].train_loader.dataset[i][1]\n",
        "  l[index]+=1\n",
        "print(\"Distribution of trainset for client \"+str(ind),l)\n",
        "\n",
        "l=[0,0,0,0,0,0,0,0,0,0]\n",
        "for i in range(len(clients_list[ind].test_loader.dataset)):\n",
        "  index=clients_list[ind].test_loader.dataset[i][1]\n",
        "  l[index]+=1\n",
        "print(\"Distribution of testset for client  \"+str(ind),l)"
      ],
      "metadata": {
        "id": "2HnJJrP3rHZd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d323ec9-ae7a-4a9e-fb17-170568551b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution of trainset for client 4 [0, 0, 0, 0, 50, 0, 0, 0, 0, 0]\n",
            "Distribution of testset for client  4 [0, 0, 0, 0, 8, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FEDERATED AVG FUNCTIONS\n",
        "\n",
        "The functions to send and calculate the avg models."
      ],
      "metadata": {
        "id": "AvQ3af1Cw887"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import random\n",
        "#https://github.com/AshwinRJ/Federated-Learning-PyTorch/blob/master/src/utils.py\n",
        "\n",
        "#Calculate AVG for each clients layers\n",
        "def average_weights(w,clients):\n",
        "    \"\"\"\n",
        "    Returns the average of the weights.\n",
        "    \"\"\"\n",
        "\n",
        "    '''\n",
        "    #IMPLEMENTATION OF FEDVC\n",
        "    w_avg = copy.deepcopy(w[0])\n",
        "    for key in w_avg.keys():\n",
        "        for i in range(1, len(w)):\n",
        "            w_avg[key] += w[i][key]\n",
        "        w_avg[key] = torch.div(w_avg[key], len(w))\n",
        "    '''\n",
        "    #IMPLEMENTATION OF FEDAVG\n",
        "    total_samples=0\n",
        "    for c in clients:\n",
        "      total_samples+=len(c.train_loader.dataset)\n",
        "\n",
        "    w_avg = copy.deepcopy(w[0])\n",
        "    for key in w_avg.keys():\n",
        "        w_avg[key] = w_avg[key]*0\n",
        "\n",
        "    for key in w_avg.keys():\n",
        "        for i in range(0, len(w)):\n",
        "            w_avg[key] += w[i][key]*len(clients[i].train_loader.dataset)\n",
        "        w_avg[key] = torch.div(w_avg[key], total_samples)\n",
        "\n",
        "    #print(w[0][\"conv1.weight\"][0][0][0][0], w_avg[\"conv1.weight\"][0][0][0][0],\"---------------------------------------------------\") \n",
        "    #print(w[1][\"conv1.weight\"][0][0][0][0], w_avg[\"conv1.weight\"][0][0][0][0],\"---------------------------------------------------\") \n",
        "    return w_avg\n",
        "\n",
        "\n",
        "#CLIENTS -> MAIN MODEL & AVERAGE\n",
        "def set_averaged_weights_as_main_model_weights_and_update_main_model(main_model,clients):\n",
        "  local_weights=[]\n",
        "  for c in clients:\n",
        "    w=c.net.state_dict()\n",
        "    local_weights.append(copy.deepcopy(w))\n",
        "\n",
        "  global_weights = average_weights(local_weights,clients) # update global weights\n",
        "  main_model.load_state_dict(global_weights)\n",
        "  return main_model\n",
        "\n",
        "\n",
        "\n",
        "#MAIN MODEL -> CLIENTS\n",
        "def send_main_model_to_nodes_and_update_clients(main_model, clients):\n",
        "    with torch.no_grad():\n",
        "      w=main_model.state_dict()\n",
        "      for i in range(len(clients)):\n",
        "        clients[i].net.load_state_dict(copy.deepcopy(w))\n",
        "    return clients\n",
        "\n",
        "\n",
        "\n",
        "#TRAIN ALL CLIENTS\n",
        "def start_train_nodes(clients):\n",
        "    for i in range(len(clients)): \n",
        "\n",
        "        clients[i].net = clients[i].net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "\n",
        "        cudnn.benchmark # Calling this optimizes runtime\n",
        "        for epoch in range(NUM_EPOCHS):    \n",
        "            for images, labels in clients[i].train_loader:\n",
        "              # Bring data over the device of choice\n",
        "              images = images.to(DEVICE)\n",
        "              labels = labels.to(DEVICE)\n",
        "\n",
        "              clients[i].net.train() # Sets module in training mode\n",
        "\n",
        "              clients[i].optimizer.zero_grad() # Zero-ing the gradients\n",
        "              # Forward pass to the network\n",
        "              outputs = clients[i].net(images)\n",
        "              # Compute loss based on output and ground truth\n",
        "              loss = clients[i].criterion(outputs, labels)\n",
        "\n",
        "              # Compute gradients for each layer and update weights\n",
        "              loss.backward()  # backward pass: computes gradients\n",
        "              clients[i].optimizer.step() # update weights based on accumulated gradients\n",
        "    return clients\n",
        "\n",
        "\n",
        "#WEIGHTED ACCURACY\n",
        "def weighted_accuracy(clients):\n",
        "  sum=0\n",
        "  num_samples=0\n",
        "  for i in range(len(clients)):\n",
        "    test_loss, test_accuracy = evaluate(clients[i].net,clients[i].criterion, clients[i].test_loader)\n",
        "    w=len(clients[i].train_loader.dataset)\n",
        "    num_samples+=w\n",
        "\n",
        "    sum=sum+test_accuracy*w\n",
        "  return sum/num_samples\n",
        "\n",
        "\n",
        "#SELECT CLIENTS\n",
        "def selectClients(clients):\n",
        "  for i in range(random.randint(2,7)):\n",
        "    random.shuffle(clients)\n",
        "\n",
        "  round_clients_list=[]\n",
        "  for i in range(NUM_SELECTED_CLIENTS):\n",
        "    round_clients_list.append(clients[i])\n",
        "  return round_clients_list"
      ],
      "metadata": {
        "id": "F4qFgEvnsFFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAIN THE SYSTEM AND TEST"
      ],
      "metadata": {
        "id": "apwItqhtyzJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#INSTANCE MAIN MODEL\n",
        "main_model=get_net()\n",
        "\n",
        "main_optimizer = torch.optim.SGD(main_model.parameters(), lr=LR, momentum=MOMENTUM)\n",
        "main_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "for i in range(ROUNDS):\n",
        "  #SELECT CLEINTS\n",
        "  round_clients_list=selectClients(clients_list)\n",
        "\n",
        "  #MAIN MODEL -> CLIENTS\n",
        "  round_clients_list=send_main_model_to_nodes_and_update_clients(main_model, round_clients_list)\n",
        "\n",
        "  #TRAIN CLIENTS\n",
        "  round_clients_list=start_train_nodes(round_clients_list)\n",
        "\n",
        "  #CLIENTS -> MAIN MODEL & AVERAGE\n",
        "  main_model= set_averaged_weights_as_main_model_weights_and_update_main_model(main_model,round_clients_list)\n",
        "\n",
        "  #TEST\n",
        "  test_loss, main_model_accuracy = evaluate(main_model,main_criterion, test_loader)\n",
        "  w_accuracy=weighted_accuracy(round_clients_list)\n",
        "  print(\"After round \"+str(i+1)+\" main model accuracy: \"+str(main_model_accuracy)+\"   weighted accuracy: \"+str(w_accuracy))\n",
        "\n",
        "print(\"-----------------------------------------\")\n",
        "print(\"Final Accuracy of Main Model Federated Learning: \"+str(main_model_accuracy))\n",
        "print(\"Final Weighted Accuracy of Federated Learning: \"+str(w_accuracy))\n",
        "print(\"Final Accuracy of standard approach: \"+str(centralized_accuracy))\n"
      ],
      "metadata": {
        "id": "oP84Zm_Wsp-L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be0695b7-dcf5-4cc5-f243-b595aeedd979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After round 1 main model accuracy: 0.0957   weighted accuracy: 0.5\n",
            "After round 2 main model accuracy: 0.1   weighted accuracy: 0.40625\n",
            "After round 3 main model accuracy: 0.1   weighted accuracy: 0.40625\n",
            "After round 4 main model accuracy: 0.1   weighted accuracy: 0.42857142857142855\n",
            "After round 5 main model accuracy: 0.1   weighted accuracy: 0.390625\n",
            "After round 6 main model accuracy: 0.1   weighted accuracy: 0.42857142857142855\n",
            "-----------------------------------------\n",
            "Final Accuracy of Main Model Federated Learning: 0.1\n",
            "Final Weighted Accuracy of Federated Learning: 0.42857142857142855\n",
            "Final Accuracy of standard approach: 0.2745\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "FedAvg Baseline.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5a492e9719734fefa09dc484a948ffd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_11d1c59cc4f64daca63f797d055c9e1f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0e4ba3ef028f41b7b19cf979909a693b",
              "IPY_MODEL_25b2c0b32e23466ab14e0801df40e6b7",
              "IPY_MODEL_94f7eb5293f1476ca5ea50da4d24f747"
            ]
          }
        },
        "11d1c59cc4f64daca63f797d055c9e1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e4ba3ef028f41b7b19cf979909a693b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_48e62ec7737a44a4b44841d448b6120a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df4441df8172419bb026a37ff075c5f8"
          }
        },
        "25b2c0b32e23466ab14e0801df40e6b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5257aa416ce94a18b593d2ae335a98fd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_76a4087ba1cf40b1bd424216d858cbbb"
          }
        },
        "94f7eb5293f1476ca5ea50da4d24f747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ee751978540d4ababba8de8f28a46232",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:02&lt;00:00, 75792646.29it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c1b1b3fb4b9a4ed0ba70eb3f587c2f96"
          }
        },
        "48e62ec7737a44a4b44841d448b6120a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df4441df8172419bb026a37ff075c5f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5257aa416ce94a18b593d2ae335a98fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "76a4087ba1cf40b1bd424216d858cbbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee751978540d4ababba8de8f28a46232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c1b1b3fb4b9a4ed0ba70eb3f587c2f96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}