{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "8PoT-skkT-GK",
        "outputId": "721e820f-93c7-436c-d861-250c1becc9aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.12.0+cu113)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision) (4.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2021.10.8)\n",
            "Collecting Pillow-SIMD\n",
            "  Downloading Pillow-SIMD-9.0.0.post1.tar.gz (849 kB)\n",
            "\u001b[K     |████████████████████████████████| 849 kB 32.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: Pillow-SIMD\n",
            "  Building wheel for Pillow-SIMD (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Pillow-SIMD: filename=Pillow_SIMD-9.0.0.post1-cp37-cp37m-linux_x86_64.whl size=1245650 sha256=95ee43a1e16239f486958eb1ea47a474995ac632908f8d9de44a094a8d839e12\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/3f/fd/ca7133b4f7f509eb1de652bb8c128529a0c04b25ef0a6c535a\n",
            "Successfully built Pillow-SIMD\n",
            "Installing collected packages: Pillow-SIMD\n",
            "Successfully installed Pillow-SIMD-9.0.0.post1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n",
            "Cloning into 'CIFAR10_Federated_Learning-Advanced_Machine_Learning'...\n",
            "remote: Enumerating objects: 921, done.\u001b[K\n",
            "remote: Counting objects: 100% (147/147), done.\u001b[K\n",
            "remote: Compressing objects: 100% (97/97), done.\u001b[K\n",
            "remote: Total 921 (delta 105), reused 85 (delta 50), pack-reused 774\u001b[K\n",
            "Receiving objects: 100% (921/921), 6.37 MiB | 6.65 MiB/s, done.\n",
            "Resolving deltas: 100% (643/643), done.\n"
          ]
        }
      ],
      "source": [
        "!pip3 install 'torch'\n",
        "!pip3 install 'torchvision'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'\n",
        "!git clone https://github.com/TM111/CIFAR10_Federated_Learning-Advanced_Machine_Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XXQHX3B2Y-_",
        "outputId": "9d77db68-ca7f-45c7-aa91-5c62e441df8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pS7mx9eUaN0r",
        "outputId": "f9f6f1c7-59ca-4249-ffe4-e04fae08e161"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'CIFAR10_Federated_Learning-Advanced_Machine_Learning/src'\n",
            "/content/CIFAR10_Federated_Learning-Advanced_Machine_Learning/src\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Train Dataset: 50000\n",
            "Test Dataset: 10000\n",
            "Distribution of trainset for client 0 [0.323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.327, 0.349] size: 269\n",
            "Distribution of testset for client 0 [0.333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.333, 0.333] size: 51\n",
            "-----------------------------------------\n",
            "Count: 9\n",
            "Local epochs: 2\n",
            "Model: LeNet5_mod\n",
            "Batch norm: 1\n",
            "Group norm: 0\n",
            "Freeze: False\n",
            "Pretrain: False\n",
            "Dataset distribution: multimodal\n",
            "Ratio:  0.25   Z: 3\n",
            "Algorithm: FedNova\n",
            "FedIR: 0    FedVC: 0\n",
            "Number of clients: 100\n",
            "Number of selected clients: 30\n",
            "Number of rounds: 30\n",
            "-----------------------------------------\n",
            "After round  1 \t server accuracy: 0.100 \t server loss: nan \t weighted accuracy: 0.103 \t train time: 9.02 sec.\n",
            "After round  2 \t server accuracy: 0.136 \t server loss: 2.428 \t weighted accuracy: 0.123 \t train time: 4.6 sec.\n",
            "After round  3 \t server accuracy: 0.180 \t server loss: 3.094 \t weighted accuracy: 0.180 \t train time: 5.23 sec.\n",
            "After round  4 \t server accuracy: 0.186 \t server loss: 2.250 \t weighted accuracy: 0.199 \t train time: 5.37 sec.\n",
            "After round  5 \t server accuracy: 0.159 \t server loss: 3.460 \t weighted accuracy: 0.162 \t train time: 5.46 sec.\n",
            "After round  6 \t server accuracy: 0.232 \t server loss: 2.153 \t weighted accuracy: 0.232 \t train time: 5.31 sec.\n",
            "After round  7 \t server accuracy: 0.158 \t server loss: 3.628 \t weighted accuracy: 0.156 \t train time: 5.58 sec.\n",
            "After round  8 \t server accuracy: 0.153 \t server loss: 2.401 \t weighted accuracy: 0.158 \t train time: 4.79 sec.\n",
            "After round  9 \t server accuracy: 0.150 \t server loss: 7.018 \t weighted accuracy: 0.143 \t train time: 4.36 sec.\n",
            "After round 10 \t server accuracy: 0.133 \t server loss: 2.514 \t weighted accuracy: 0.136 \t train time: 4.37 sec.\n",
            "After round 11 \t server accuracy: 0.182 \t server loss: 3.193 \t weighted accuracy: 0.174 \t train time: 5.1 sec.\n",
            "After round 12 \t server accuracy: 0.290 \t server loss: 2.044 \t weighted accuracy: 0.284 \t train time: 6.1 sec.\n",
            "Traceback (most recent call last):\n",
            "  File \"baseline_main.py\", line 89, in <module>\n",
            "    selected_clients = train_clients(selected_clients)\n",
            "  File \"/content/CIFAR10_Federated_Learning-Advanced_Machine_Learning/src/utils.py\", line 201, in train_clients\n",
            "    for images, labels in loader:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 530, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 570, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\", line 471, in __getitem__\n",
            "    return self.dataset[self.indices[idx]]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchvision/datasets/cifar.py\", line 118, in __getitem__\n",
            "    img = self.transform(img)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n",
            "    img = t(img)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\", line 135, in __call__\n",
            "    return F.to_tensor(pic)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\", line 151, in to_tensor\n",
            "    img = img.view(pic.size[1], pic.size[0], len(pic.getbands()))\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "#-9---\n",
        "%cd CIFAR10_Federated_Learning-Advanced_Machine_Learning/src\n",
        "!python baseline_main.py \\\n",
        "--COUNT=9 \\\n",
        "--MODEL='LeNet5_mod' \\\n",
        "--PRETRAIN=0 \\\n",
        "--FREEZE=0 \\\n",
        "--BATCH_NORM=1 \\\n",
        "--NUM_EPOCHS=3 \\\n",
        "--ALGORITHM='FedNova' \\\n",
        "--FEDIR=0 \\\n",
        "--FEDVC=0 \\\n",
        "--DISTRIBUTION='multimodal' \\\n",
        "--ALPHA=0 \\\n",
        "--NUM_CLIENTS=100 \\\n",
        "--NUM_SELECTED_CLIENTS=25 \\\n",
        "--ROUNDS=25 \\\n",
        "--DEVICE='cuda' \\\n",
        "--COLAB=1 \\\n",
        "--RATIO=0.25 \\\n",
        "--Z=3\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "PYTHON3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}